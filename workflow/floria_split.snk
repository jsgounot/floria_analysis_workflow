import glob, os, json
from scripts import utilities

wildcard_constraints:
    vcaller="longshot|lofreq|binocustom",
    rtype="long_reads|short_reads"

# ------------------------------------------------------------------------------------------------------------------------------------------
# Execution

rule floria:
    input:
        exe   = config['softparams']['soft']['floria'],
        fasta = 'kraken/{group}/split/bamfa/{tid}.{krtype}.fa',
        fai   = 'kraken/{group}/split/bamfa/{tid}.{krtype}.fa.fai',
        bam   = 'kraken/{group}/split/bamfa/{tid}.{krtype}.sorted.bam',
        bai   = 'kraken/{group}/split/bamfa/{tid}.{krtype}.sorted.bam.bai',
        vcf   = 'vcalling/{group}/split/{tid}.{krtype}.{vcaller}.floria_vcf_header'
    output:
        directory('phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/wdir/')
    conda:
        config['softparams']['conda']['floria']
    threads:
        utilities.get_generic_threads_split
    log:
        'logs/{group}/floria.split.{krtype}.{tid}.{vcaller}.log'
    benchmark:
        'benchmarks/{group}/floria.split.{krtype}.{tid}.{vcaller}.txt'
    shell:
        '{input.exe} -b {input.bam} -v {input.vcf} -o {output} -t {threads} -r {input.fasta} \
            --output-reads --gzip-reads > {log}'

# ------------------------------------------------------------------------------------------------------------------------------------------
# Post-processing
# This part is made to compress all directory for both space and files number reduction

rule compress_floria_subdir:
    input:
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/wdir/'
    output:
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.{dirname}.tar.gz'
    params:
        path = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/wdir/*/{dirname}'
    shell:
        'tar -czf {output} {params.path} --remove-files'

rule prep_floria_outputs:
    input:
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.vartig_info.tar.gz',
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.local_parts.tar.gz',
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.long_reads.tar.gz',
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.short_reads.tar.gz',
    output:
        touch('phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/prep.done')
    priority:
        1

# ------------------------------------------------------------------------------------------------------------------------------------------
# Assembly

# I end up using a script for each assembly process here to make all the assemblies with one single rule
# as fast, not overloading output, still work asynchroniously. Best decision I took during the last months

# Note regarding unicyler
# I decided to not use it because unicycler uses Spades under the hood
# which is perfectly fine with regular good coverage genomes
# but crashes when coverage is low which happens quite a lot when
# dealing with this kind of cases (or short-binning as well for example)
# I'm using abysspe instead but maybe something better could be use

WTDBG2PRESETS = {
    'hifi': '-x ccs -R',
    'nano': '-x preset2 -e 5 -l 1000 -L 3000 -S 1 -R'
}

rule uncompress:
    input:
        #archives = rules.prep_floria_outputs.output,
        rtype_ar = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.{rtype}.tar.gz'
    output:
        temp(touch('phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.{rtype}.{assembler}.uncompressed'))
    shell:
        'tar xzf {input.rtype_ar} --transform "s/fastq.gz/{wildcards.assembler}.fastq.gz/"'

rule wtdbg2:
    input:
        reads_ar = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.{rtype}.tar.gz',
        flag = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.{rtype}.wtdbg2.uncompressed'
    output:
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/assembly.wtdbg2.{rtype}.{preset}.fa.gz'
    threads:
        utilities.get_generic_threads_split
    params:
        preset = lambda wc: WTDBG2PRESETS[wc.preset]
    conda:
        config['softparams']['conda']['wtdbg2']
    log:
        'logs/{group}/floria.split.{krtype}.{tid}.{vcaller}.{rtype}.{preset}.wtdbg2.log'
    benchmark:
        'benchmarks/{group}/floria.split.{krtype}.{tid}.{vcaller}.{rtype}.{preset}.wtdbg2.txt'
    script:
        'scripts/floria_run_wtdbg2.py'

rule abysspe:
    input:
        reads_ar = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.{rtype}.tar.gz',
        flag = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.{rtype}.abysspe.uncompressed'
    output:
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/assembly.abysspe.{rtype}.none.fa.gz'
    threads:
        utilities.get_generic_threads_split
    conda:
        config['softparams']['conda']['abyss']
    log:
        'logs/{group}/floria.split.{krtype}.{tid}.{vcaller}.{rtype}.abysspe.log'
    benchmark:
        'benchmarks/{group}/floria.split.{krtype}.{tid}.{vcaller}.{rtype}.abysspe.log'
    script:
        'scripts/floria_run_abysspe.py'

def get_assemblies(wc):
    with checkpoints.kr_split_list_contigs.get(** wc).output[0].open() as f:
        tids = [line.strip() for line in f]

    return [f'phasing/floria/split/{wc.group}/{wc.krtype}/{tid}/{wc.vcaller}/assembly.{wc.assembler}.{wc.rtype}.{wc.preset}.fa.gz'
        for tid in tids]

rule merge_tids_assemblies:
    input:
        get_assemblies
    output:
        'temp/assemblies/{group}/kraken_ref.{krtype}.{vcaller}.floria.{assembler}.{rtype}.{preset}.fa'
    shell:
        'zcat {input} > {output}'