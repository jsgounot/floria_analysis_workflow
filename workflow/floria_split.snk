import glob, os, json
from scripts import utilities

# ------------------------------------------------------------------------------------------------------------------------------------------
# Execution

FMODES = {
    'fp0': '-l 100 -d 0.0001',
    'fp1': '-l 100 -d 0.0005 -e 0.01'
}

rule floria:
    input:
        fasta = 'kraken/{group}/split/bamfa/{tid}.{krtype}.fa',
        fai   = 'kraken/{group}/split/bamfa/{tid}.{krtype}.fa.fai',
        bam   = 'kraken/{group}/split/bamfa/{tid}.{krtype}.bam',
        bai   = 'kraken/{group}/split/bamfa/{tid}.{krtype}.bam.bai',
        vcf   = 'vcalling/{group}/split/{tid}.{krtype}.{vcaller}.floria_vcf_header'
    output:
        directory('phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/wdir/{fmode}/')
    params:
        exe = utilities.get_softpath(config, 'floria'),
        extra_params = lambda wc: FMODES[wc.fmode] if wc.fmode != 'none' else ''
    conda:
        config['softparams']['conda']['floria']
    threads:
        config['miscs']['GENERIC_THREADS_SPLIT']
    log:
        'logs/{group}/floria.{fmode}.split.{krtype}.{tid}.{vcaller}.log'
    benchmark:
        'benchmarks/{group}/floria.{fmode}.split.{krtype}.{tid}.{vcaller}.txt'
    shell:
        '{params.exe} -b {input.bam} -v {input.vcf} -o {output} -t {threads} -r {input.fasta} \
            --output-reads --gzip-reads {params.extra_params} > {log}'

# ------------------------------------------------------------------------------------------------------------------------------------------
# Post-processing
# This part is made to compress all directory for both space and files number reduction

rule mv_compress:
    # We need to mv first to avoid snakemake to get confused with timestamps
    input:
        rules.floria.output[0]
    output:
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/wdir.{fmode}.tar.gz'
    params:
        dname = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/done/{fmode}'
    priority:
        1
    shell:
        'rm -rf {params.dname} && mkdir -p {params.dname} && mv {input} {params.dname} && tar czf {output} {params.dname} --remove-files'

rule uncompress:
    input:
        rules.mv_compress.output[0]
    output:
        temp(touch('phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.{fmode}.{rtype}.{assembler}.uncompressed'))
    shell:
        'tar xzf {input} --transform "s/fastq.gz/{wildcards.assembler}.fastq.gz/" --wildcards "*/{wildcards.rtype}/*.fastq.gz"'

rule ploidy_table:
    input:
        archive = rules.mv_compress.output[0],
        fasta = 'kraken/{group}/split/bamfa/{tid}.{krtype}.fa',
        kraken = 'kraken/{group}/kraken.{krtype}.report.cov.tsv',
        depth = 'kraken/{group}/split/bamfa/{tid}.{krtype}.bam.cov.tsv.gz',
        vcf = 'vcalling/{group}/split/{tid}.{krtype}.{vcaller}.floria_vcf_header'
    output:
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/ploidy.{fmode}.tsv.gz'
    script:
        'scripts/floria_ploidy_table.py'

rule cluster_info_bam:
    input:
        archive = rules.mv_compress.output[0],
        bam = 'kraken/{group}/split/bamfa/{tid}.{krtype}.bam'
    output:
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/cluster_info.{fmode}.tsv.gz'
    conda:
        config['softparams']['conda']['strainberry'] # pysam
    script:
        'scripts/floria_cluster_info_bam.py'

# ------------------------------------------------------------------------------------------------------------------------------------------
# Assembly

# I end up using a script for each assembly process here to make all the assemblies with one single rule
# as fast, not overloading output, still work asynchroniously. Best decision I took during the last months

# Note regarding unicyler
# I decided to not use it because unicycler uses Spades under the hood
# which is perfectly fine with regular good coverage genomes
# but crashes when coverage is low which happens quite a lot when
# dealing with this kind of cases (or short-binning as well for example)
# I'm using abysspe instead but maybe something better could be use

WTDBG2PRESETS = {
    'hifi': '-x ccs -R',
    'nano': '-x preset2 -e 5 -l 1000 -L 3000 -S 1 -R'
}

rule inference:
    input:
        reads_ar = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/wdir.{fmode}.tar.gz',
        fasta = 'kraken/{group}/split/bamfa/{tid}.{krtype}.fa',
        vcf = 'vcalling/{group}/split/{tid}.{krtype}.{vcaller}.floria_vcf_header.gz',
        tab = 'vcalling/{group}/split/{tid}.{krtype}.{vcaller}.floria_vcf_header.gz.tbi'
    output:
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/assembly.{fmode}.inference.none.none.fa.gz'
    params:
        default_ref = True,
        add_nocov = True
    log:
        'logs/{group}/floria.{fmode}.split.{krtype}.{tid}.{vcaller}.inference.log'
    benchmark:
        'benchmarks/{group}/floria.{fmode}.split.{krtype}.{tid}.{vcaller}.inference.txt'
    script:
        'scripts/floria_run_inference.py'

rule wtdbg2:
    input:
        reads_ar = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/wdir.{fmode}.tar.gz',
        flag = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.{fmode}.{rtype}.wtdbg2.uncompressed'
    output:
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/assembly.{fmode}.wtdbg2.{rtype}.{preset}.fa.gz'
    threads:
        config['miscs']['GENERIC_THREADS_SPLIT']
    params:
        preset = lambda wc: WTDBG2PRESETS[wc.preset]
    conda:
        config['softparams']['conda']['wtdbg2']
    log:
        'logs/{group}/floria.{fmode}.split.{krtype}.{tid}.{vcaller}.{rtype}.{preset}.wtdbg2.log'
    benchmark:
        'benchmarks/{group}/floria.{fmode}.split.{krtype}.{tid}.{vcaller}.{rtype}.{preset}.wtdbg2.txt'
    script:
        'scripts/floria_run_wtdbg2.py'

rule flye:
    input:
        reads_ar = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/wdir.{fmode}.tar.gz',
        flag = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.{fmode}.{rtype}.flye.uncompressed'
    output:
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/assembly.{fmode}.flye.{rtype}.none.fa.gz'
    threads:
        config['miscs']['GENERIC_THREADS_SPLIT']
    params:
        kmersize = 16
    conda:
        config['softparams']['conda']['flye']
    log:
        'logs/{group}/floria.{fmode}.split.{krtype}.{tid}.{vcaller}.{rtype}.flye.log'
    benchmark:
        'benchmarks/{group}/floria.{fmode}.split.{krtype}.{tid}.{vcaller}.{rtype}.flye.txt'
    script:
        'scripts/floria_run_flye.py'

rule abysspe:
    input:
        reads_ar = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/wdir.{fmode}.tar.gz',
        flag = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.{fmode}.{rtype}.abysspe.uncompressed'
    output:
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/assembly.{fmode}.abysspe.{rtype}.none.fa.gz'
    threads:
        config['miscs']['GENERIC_THREADS_SPLIT']
    conda:
        config['softparams']['conda']['abyss']
    log:
        'logs/{group}/floria.{fmode}.split.{krtype}.{tid}.{vcaller}.{rtype}.abysspe.log'
    benchmark:
        'benchmarks/{group}/floria.{fmode}.split.{krtype}.{tid}.{vcaller}.{rtype}.abysspe.txt'
    script:
        'scripts/floria_run_abysspe.py'

rule megahit:
    input:
        reads_ar = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/wdir.{fmode}.tar.gz',
        flag = 'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/floria.{fmode}.{rtype}.megahit.uncompressed'
    output:
        'phasing/floria/split/{group}/{krtype}/{tid}/{vcaller}/assembly.{fmode}.megahit.{rtype}.none.fa.gz'
    threads:
        config['miscs']['GENERIC_THREADS_SPLIT']
    conda:
        config['softparams']['conda']['megahit']
    log:
        'logs/{group}/floria.{fmode}.split.{krtype}.{tid}.{vcaller}.{rtype}.megahit.log'
    benchmark:
        'benchmarks/{group}/floria.{fmode}.split.{krtype}.{tid}.{vcaller}.{rtype}.megahit.txt'
    script:
        'scripts/floria_run_megahit.py'

# ------------------------------------------------------------------------------------------------------------------------------------------
# Merging

def get_assemblies(wc):
    with checkpoints.kr_split_fasta.get(** wc).output[0].open() as f:
        tids = [line.strip() for line in f]

    return [f'phasing/floria/split/{wc.group}/{wc.krtype}/{tid}/{wc.vcaller}/assembly.{wc.fmode}.{wc.assembler}.{wc.rtype}.{wc.preset}.fa.gz'
        for tid in tids]

rule merge_tids_assemblies:
    input:
        get_assemblies
    output:
        'temp/assemblies/{group}/kraken_ref.{krtype}.{vcaller}.floria.{fmode}.{assembler}.{rtype}.{preset}.fa'
    wildcard_constraints:
        vcaller="longshot|lofreq|binocustom|freebayes",
        rtype="long_reads|short_reads|none"
    shell:
        'zcat {input} > {output}'

def get_clusters_info(wc):
    with checkpoints.kr_split_fasta.get(** wc).output[0].open() as f:
        tids = [line.strip() for line in f]

    return [f'phasing/floria/split/{wc.group}/{wc.krtype}/{tid}/{wc.vcaller}/cluster_info.{wc.fmode}.tsv.gz'
        for tid in tids]

rule merge_cluster_infos:
    input:
        cinfos = get_clusters_info,
        reads = lambda wc: utilities.get_reads(wc.group, wc.krtype)
    output:
        'stats/floria/{group}/kraken_ref.{krtype}.{vcaller}.floria.{fmode}.tsv.gz'
    wildcard_constraints:
        vcaller="longshot|lofreq|binocustom|freebayes",
        rtype="long_reads|short_reads|none"
    script:
        'scripts/floria_merge_cluster_infos.py'